import os
from typing import List
from dataclasses import dataclass
from datetime import datetime

from langchain_community.embeddings import OpenAIEmbeddings
# LangChain ç›¸å…³å¯¼å…¥
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from llama_index.llms.openai import OpenAI


@dataclass
class SourceInfo:
    """æ•°æ®æºä¿¡æ¯"""
    url: str
    title: str
    content: str
    timestamp: datetime

class SimpleRAGSystem:
    """åŸºäº LangChain çš„ç®€å• RAG ç³»ç»Ÿ"""
    
    def __init__(self, openai_api_key: str = None):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.api_key = openai_api_key or "sk-1J2fBiacH6vgheGh1eR8jpmZMHVNGyz1A2uU9zVq3uVeDW5P"
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.embeddings = OpenAIEmbeddings(openai_api_key=self.api_key)
        self.llm = OpenAI(
            model="gpt-3.5-turbo-instruct",
            openai_api_key=self.api_key,
            temperature=0
        )
        
        # æ–‡æœ¬åˆ†å‰²å™¨ï¼ˆLlamaIndexï¼šç›´æ¥ä½¿ç”¨æ•´ä¸ªæ–‡æ¡£å†…å®¹ï¼Œä¸è¿›è¡Œåˆ†å—ï¼‰
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
        # å‘é‡å­˜å‚¨
        self.vectorstore = None
        self.qa_chain = None
        
        # æç¤ºæ¨¡æ¿ï¼ˆç›¸è¾ƒäº llamaindexï¼Œè¿™é‡Œå®šä¹‰äº†è¯¦ç»†çš„æç¤ºæ¨¡æ¿ï¼ŒåŒ…å«éªŒè¯ç»“æœã€ç½®ä¿¡åº¦ã€æ¨ç†è¿‡ç¨‹å’Œè¯æ®æ¥æºç­‰ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ï¼‰
        self.prompt_template = PromptTemplate(
            input_variables=["context", "question"],
            template="""
ä½ æ˜¯ä¸€ä¸ªäº‹å®éªŒè¯ä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
éªŒè¯ç»“æœï¼š[çœŸå®/è™šå‡/ä¸ç¡®å®š]
ç½®ä¿¡åº¦ï¼š[0-100%]
æ¨ç†è¿‡ç¨‹ï¼š[è¯¦ç»†è¯´æ˜æ¨ç†è¿‡ç¨‹]
è¯æ®æ¥æºï¼š[å¼•ç”¨å…·ä½“çš„è¯æ®ç‰‡æ®µ]
"""
        )
    
    def get_knowledge_sources(self) -> List[SourceInfo]:
        """è·å–çŸ¥è¯†æºï¼ˆä½¿ç”¨é¢„å®šä¹‰å†…å®¹ï¼Œé¿å…ç½‘ç»œçˆ¬å–çš„å¤æ‚æ€§ï¼‰"""
        sources = [
            SourceInfo(
                url="https://zh.wikipedia.org/wiki/äººå·¥æ™ºèƒ½",
                title="äººå·¥æ™ºèƒ½ - ç»´åŸºç™¾ç§‘",
                content="""
                äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼ŒAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œ
                è‡´åŠ›äºåˆ›é€ èƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„æœºå™¨å’Œè½¯ä»¶ã€‚
                
                äººå·¥æ™ºèƒ½çš„ä¸»è¦é¢†åŸŸåŒ…æ‹¬ï¼š
                1. æœºå™¨å­¦ä¹ ï¼šè®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼å’Œè§„å¾‹
                2. æ·±åº¦å­¦ä¹ ï¼šä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œè¿›è¡Œå¤æ‚æ¨¡å¼è¯†åˆ«
                3. è‡ªç„¶è¯­è¨€å¤„ç†ï¼šè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€
                4. è®¡ç®—æœºè§†è§‰ï¼šè®©è®¡ç®—æœºç†è§£å’Œåˆ†æå›¾åƒå’Œè§†é¢‘
                5. ä¸“å®¶ç³»ç»Ÿï¼šåŸºäºè§„åˆ™å’ŒçŸ¥è¯†çš„å†³ç­–ç³»ç»Ÿ
                
                å…³äºäººå·¥æ™ºèƒ½æ˜¯å¦ä¼šåœ¨æœªæ¥åå¹´å†…è¶…è¶Šäººç±»æ™ºèƒ½ï¼Œå­¦æœ¯ç•Œå­˜åœ¨å¾ˆå¤§äº‰è®®ã€‚
                ä¸€äº›ä¸“å®¶è®¤ä¸ºé€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„å®ç°è¿˜éœ€è¦æ•°åå¹´æ—¶é—´ï¼Œ
                è€Œå¦ä¸€äº›ä¸“å®¶åˆ™è®¤ä¸ºå¯èƒ½åœ¨æ›´çŸ­æ—¶é—´å†…å®ç°çªç ´ã€‚
                ç›®å‰çš„AIç³»ç»Ÿåœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨é€šç”¨æ™ºèƒ½æ–¹é¢ä»æœ‰å¾ˆå¤§å·®è·ã€‚
                """,
                timestamp=datetime.now()
            ),
            SourceInfo(
                url="https://zh.wikipedia.org/wiki/æœºå™¨å­¦ä¹ ",
                title="æœºå™¨å­¦ä¹  - ç»´åŸºç™¾ç§‘", 
                content="""
                æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œä¸“æ³¨äºå¼€å‘èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å’Œæ”¹è¿›çš„ç®—æ³•ã€‚
                
                æœºå™¨å­¦ä¹ ä¸äººå·¥æ™ºèƒ½çš„å…³ç³»ï¼š
                - äººå·¥æ™ºèƒ½æ˜¯æ›´å¹¿æ³›çš„æ¦‚å¿µï¼ŒåŒ…æ‹¬æ‰€æœ‰æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æŠ€æœ¯
                - æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„ä¸»è¦æ–¹æ³•ä¹‹ä¸€
                - æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸ
                
                å±‚æ¬¡å…³ç³»ï¼šäººå·¥æ™ºèƒ½ > æœºå™¨å­¦ä¹  > æ·±åº¦å­¦ä¹ 
                
                æœºå™¨å­¦ä¹ çš„ä¸»è¦ç±»å‹ï¼š
                1. ç›‘ç£å­¦ä¹ ï¼šä½¿ç”¨æ ‡è®°æ•°æ®è¿›è¡Œè®­ç»ƒ
                2. æ— ç›‘ç£å­¦ä¹ ï¼šä»æœªæ ‡è®°æ•°æ®ä¸­å‘ç°æ¨¡å¼
                3. å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡è¯•é”™å­¦ä¹ æœ€ä¼˜ç­–ç•¥
                
                å¸¸ç”¨ç®—æ³•åŒ…æ‹¬çº¿æ€§å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œç­‰ã€‚
                """,
                timestamp=datetime.now()
            ),
            SourceInfo(
                url="https://zh.wikipedia.org/wiki/æ·±åº¦å­¦ä¹ ",
                title="æ·±åº¦å­¦ä¹  - ç»´åŸºç™¾ç§‘",
                content="""
                æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å¤æ‚è¡¨ç¤ºã€‚
                
                æ·±åº¦å­¦ä¹ ç¡®å®æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸã€‚è¿™ç§å±‚æ¬¡å…³ç³»æ˜¯æ˜ç¡®çš„ï¼š
                - äººå·¥æ™ºèƒ½æ˜¯æœ€å¹¿æ³›çš„æ¦‚å¿µ
                - æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯
                - æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªä¸“é—¨é¢†åŸŸ
                
                æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µï¼š
                1. ç¥ç»ç½‘ç»œï¼šæ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒçš„è®¡ç®—æ¨¡å‹
                2. åå‘ä¼ æ’­ï¼šè®­ç»ƒç¥ç»ç½‘ç»œçš„æ ¸å¿ƒç®—æ³•
                3. å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼šä¸»è¦ç”¨äºå›¾åƒå¤„ç†
                4. å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼šç”¨äºå¤„ç†åºåˆ—æ•°æ®
                5. å˜æ¢å™¨ï¼ˆTransformerï¼‰ï¼šç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†
                
                æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
                """,
                timestamp=datetime.now()
            ),
            SourceInfo(
                url="https://zh.wikipedia.org/wiki/Python",
                title="Python - ç»´åŸºç™¾ç§‘",
                content="""
                Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚
                
                Pythonåœ¨æ•°æ®ç§‘å­¦é¢†åŸŸçš„åœ°ä½ï¼š
                Pythonç¡®å®æ˜¯æ•°æ®ç§‘å­¦ä¸­æœ€æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ä¹‹ä¸€ã€‚æ ¹æ®å¤šé¡¹è°ƒæŸ¥å’Œç»Ÿè®¡ï¼š
                
                1. Stack Overflow å¼€å‘è€…è°ƒæŸ¥æ˜¾ç¤ºï¼ŒPythonåœ¨æ•°æ®ç§‘å­¦å®¶ä¸­ä½¿ç”¨ç‡æœ€é«˜
                2. Kaggle æ•°æ®ç§‘å­¦å¹³å°çš„è°ƒæŸ¥æ˜¾ç¤ºï¼Œè¶…è¿‡80%çš„æ•°æ®ç§‘å­¦å®¶ä½¿ç”¨Python
                3. GitHubä¸Šæ•°æ®ç§‘å­¦ç›¸å…³é¡¹ç›®ä¸­ï¼ŒPythoné¡¹ç›®æ•°é‡æœ€å¤š
                
                Pythonåœ¨æ•°æ®ç§‘å­¦ä¸­çš„ä¼˜åŠ¿ï¼š
                - è¯­æ³•ç®€æ´æ˜“è¯»ï¼Œå­¦ä¹ æ›²çº¿å¹³ç¼“
                - ä¸°å¯Œçš„æ•°æ®ç§‘å­¦åº“ç”Ÿæ€ç³»ç»Ÿï¼ˆpandas, numpy, scikit-learnç­‰ï¼‰
                - å¼ºå¤§çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆTensorFlow, PyTorchç­‰ï¼‰
                - ä¼˜ç§€çš„æ•°æ®å¯è§†åŒ–å·¥å…·ï¼ˆmatplotlib, seabornç­‰ï¼‰
                - æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒ
                
                ä¸»è¦ç«äº‰å¯¹æ‰‹åŒ…æ‹¬Rè¯­è¨€ã€SQLã€Javaç­‰ï¼Œä½†Pythonåœ¨ç»¼åˆèƒ½åŠ›ä¸Šé¢†å…ˆã€‚
                """,
                timestamp=datetime.now()
            )
        ]
        return sources
    
    def build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“"""
        print("ğŸ”§ æ­£åœ¨æ„å»ºçŸ¥è¯†åº“...")
        
        # è·å–çŸ¥è¯†æº
        sources = self.get_knowledge_sources()
        
        # åˆ›å»ºæ–‡æ¡£
        documents = []
        for source in sources:
            # åˆ†å‰²æ–‡æœ¬
            chunks = self.text_splitter.split_text(source.content)
            
            for chunk in chunks:
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "source": source.url,
                        "title": source.title,
                        "timestamp": source.timestamp.isoformat()
                    }
                )
                documents.append(doc)
        
        # åˆ›å»ºå‘é‡å­˜å‚¨
        self.vectorstore = FAISS.from_documents(documents, self.embeddings)
        
        # åˆ›å»ºæ£€ç´¢QAé“¾ï¼Œé…åˆè‡ªå®šä¹‰æç¤ºæ¨¡æ¿ï¼ˆLlamaIndex ç›´æ¥ä½¿ç”¨æŸ¥è¯¢ï¼‰
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.vectorstore.as_retriever(search_kwargs={"k": 3}),
            chain_type_kwargs={"prompt": self.prompt_template},
            return_source_documents=True
        )
        
        print(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
    
    def ask_question(self, question: str):
        """è¯¢é—®é—®é¢˜å¹¶è·å–ç­”æ¡ˆ"""
        if not self.qa_chain:
            raise ValueError("çŸ¥è¯†åº“æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ build_knowledge_base()")
        
        print(f"â“ é—®é¢˜ï¼š{question}")
        print("ğŸ¤” æ­£åœ¨æ€è€ƒ...")
        
        # è·å–ç­”æ¡ˆ
        result = self.qa_chain({"query": question})
        answer = result["result"]
        source_docs = result["source_documents"]
        
        # æ˜¾ç¤ºç­”æ¡ˆ
        print(f"ğŸ¤– AIå›ç­”ï¼š")
        print(answer)
        
        # æ˜¾ç¤ºè¯æ®æ¥æº
        if source_docs:
            print("\nğŸ“š è¯æ®æ¥æºï¼š")
            for i, doc in enumerate(source_docs, 1):
                print(f"   {i}. {doc.metadata.get('title', 'æœªçŸ¥æ¥æº')}")
                print(f"      ğŸ”— {doc.metadata.get('source', 'æ— é“¾æ¥')}")
                print(f"      ğŸ“„ å†…å®¹ç‰‡æ®µï¼š{doc.page_content[:200]}...")
                print()
        
        return answer, source_docs

# ä¸»å‡½æ•° - æ¼”ç¤ºç³»ç»ŸåŠŸèƒ½
def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºåŸºäºLangChainçš„RAGç³»ç»Ÿ"""
    print("=== åŸºäº LangChain çš„ç®€å• RAG ç³»ç»Ÿæ¼”ç¤º ===\n")
    
    # 1. æ£€æŸ¥APIå¯†é’¥
    openai_api_key = "sk-1J2fBiacH6vgheGh1eR8jpmZMHVNGyz1A2uU9zVq3uVeDW5P"
    if not openai_api_key:
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    # 2. åˆ›å»ºRAGç³»ç»Ÿ
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
    rag_system = SimpleRAGSystem(openai_api_key=openai_api_key)
    
    # 3. æ„å»ºçŸ¥è¯†åº“
    rag_system.build_knowledge_base()
    
    # 4. å®šä¹‰æµ‹è¯•é—®é¢˜
    questions = [
        "äººå·¥æ™ºèƒ½å°†åœ¨æœªæ¥åå¹´å†…è¶…è¶Šäººç±»æ™ºèƒ½å—ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸå—ï¼Ÿ", 
        "Pythonæ˜¯æ•°æ®ç§‘å­¦ä¸­æœ€æµè¡Œçš„è¯­è¨€å—ï¼Ÿ"
    ]
    
    print("\n=== å¼€å§‹é—®ç­”æ¼”ç¤º ===\n")
    
    # 5. é€ä¸€æé—®
    for i, question in enumerate(questions, 1):
        print(f"{'='*60}")
        print(f"ç¬¬ {i} ä¸ªé—®é¢˜")
        print(f"{'='*60}")
        
        try:
            answer, sources = rag_system.ask_question(question)
            print(f"{'='*60}\n")
            
        except Exception as e:
            print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
            print(f"{'='*60}\n")
    
    print("âœ¨ RAGç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤ºç¨‹åº
    main()