{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4545453cd966e0ac",
   "metadata": {},
   "source": [
    "# 1.PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdb384189dc367",
   "metadata": {},
   "source": "## 1.1、使用说明"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " - PromptTemplate类,用于快速构建 **包含变量** 的提示词模板,并通过 **传入不同的参数值** 生成自定义的提示词\n",
    " - 主要参数介绍\n",
    "  - template: 定义提示词模板的字符串,包含文本和变量占位符\n",
    "  - input_variables: 变量列表,指定模板中使用的变量名称,在调用模板时被替换\n",
    "  - partial_variables: 变量字典,用于定义模板中一些固定的变量名,这些变量不需要在每次调用时被替换\n",
    " - 函数介绍:\n",
    "  - format():\n",
    "    - 给input_variables变量赋值,并返回模板格式化后的字符串\n",
    "    - 使用format()格式化时就一定要赋值,不然会报错"
   ],
   "id": "70182a159d081ead"
  },
  {
   "cell_type": "markdown",
   "id": "56f3a9999b239493",
   "metadata": {},
   "source": [
    "## 1.2、PromptTemplate的实例化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe584e9a3f02c1",
   "metadata": {},
   "source": [
    "- 1）使用PromptTemplate构造方法"
   ]
  },
  {
   "cell_type": "code",
   "id": "53740af30fc26aab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:29:06.017489Z",
     "start_time": "2025-11-05T09:29:06.012097Z"
    }
   },
   "source": [
    "from itertools import product\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"你叫{name},是一个{personality}的{role}\",\n",
    "    input_variables={\"name\", \"personality\", \"role\"}\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(name = \"小智\", personality = \"博学多才,耐心细致\", role = \"人工智能领域的专家\")\n",
    "\n",
    "print(prompt)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你叫小智,是一个博学多才,耐心细致的人工智能领域的专家\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "id": "51f4b37a12fcad67",
   "metadata": {},
   "source": [
    "- 2）调用from_template()"
   ]
  },
  {
   "cell_type": "code",
   "id": "adae8ddc077cec20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:29:08.897877Z",
     "start_time": "2025-11-05T09:29:08.885084Z"
    }
   },
   "source": [
    "prompt_template2 = PromptTemplate.from_template(\"你叫{name},是一个{personality}的{role}\")\n",
    "\n",
    "prompt2 = prompt_template2.format(name=\"阿智\", personality=\"追求极致\", role=\"AI应用开发工程师\")\n",
    "print(prompt2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你叫阿智,是一个追求极致的AI应用开发工程师\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "id": "96093a09820390a5",
   "metadata": {},
   "source": [
    "模板支持任意数量的变量，包括不含变量："
   ]
  },
  {
   "cell_type": "code",
   "id": "a98e955ad971a32f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:29:10.999473Z",
     "start_time": "2025-11-05T09:29:10.994654Z"
    }
   },
   "source": [
    "# 定义提示词模版对象\n",
    "text = \"\"\"\n",
    "Tell me a joke\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(text)\n",
    "# 默认使用f-string进行格式化（返回格式好的字符串）\n",
    "prompt = prompt_template.format()\n",
    "print(prompt)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tell me a joke\n",
      "\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "id": "955d562d4ffb97e7",
   "metadata": {},
   "source": [
    "## 1.3、部分提示词模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e13d64227a43d",
   "metadata": {},
   "source": [
    "- 在生成Prompt前,就提前初始化 部分提示词,实际进一步导入模板时 只导入除已初始化的变量即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67183f273cd7dc",
   "metadata": {},
   "source": [
    "示例1: 实例化Prompt时使用partial_variables变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "844c71f6298613e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T01:39:24.599159Z",
     "start_time": "2025-11-05T01:39:24.586115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_prompt: 请介绍下小米手机各方面的特点,比如: 电池续航,像素,屏幕大小\n"
     ]
    }
   ],
   "source": [
    "partial_prompt1 = PromptTemplate.from_template(\n",
    "    template=\"请介绍下{product}各方面的特点,比如: {aspect1},{aspect2},{aspect3}\",\n",
    "    partial_variables={\"product\": \"小米手机\", \"aspect1\": \"电池续航\",\"aspect2\":\"像素\",\"aspect3\": \"屏幕大小\"},   # partial_variables: dict[str, Any] | None = None,\n",
    ")\n",
    "prompt = partial_prompt1.format()\n",
    "print(f\"partial_prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffafb56897f8",
   "metadata": {},
   "source": [
    "实例2: 使用partial()方法创建部分提示模板"
   ]
  },
  {
   "cell_type": "code",
   "id": "c791cbdc37db7c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:29:17.183266Z",
     "start_time": "2025-11-05T09:29:17.176926Z"
    }
   },
   "source": [
    "partial_prompt2 = PromptTemplate(\n",
    "    template=\"请介绍下{product}各方面的特点,比如: {aspect1},{aspect2},{aspect3}\",\n",
    "    input_variables=[\"product\",\"aspect1\",\"aspect2\",\"aspect3\"]\n",
    ").partial(\n",
    "    product=\"小米手机\",\n",
    "    aspect1=\"电池续航\",\n",
    "    aspect2=\"像素\",\n",
    "    aspect3=\"屏幕大小\")\n",
    "\n",
    "prompt2 = partial_prompt2.format()\n",
    "print(f\"partial_prompt2:{prompt2}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_prompt2:请介绍下小米手机各方面的特点,比如: 电池续航,像素,屏幕大小\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "id": "8a283df0396e6c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:29:18.987332Z",
     "start_time": "2025-11-05T09:29:18.969384Z"
    }
   },
   "source": [
    "partial_prompt3 = PromptTemplate(\n",
    "    template=\"请介绍下{product}各方面的特点,比如: {aspect1},{aspect2},{aspect3}\",\n",
    "    input_variables=[\"product\",\"aspect1\",\"aspect2\",\"aspect3\"]\n",
    ").partial(\n",
    "    aspect1=\"电池续航\",\n",
    "    aspect2=\"像素\")\n",
    "# 设置其他属性\n",
    "prompt3 = partial_prompt3.format(product=\"华为手机\",aspect3=\"屏幕大小\")\n",
    "print(f\"partial_prompt3:{prompt3}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_prompt3:请介绍下华为手机各方面的特点,比如: 电池续航,像素,屏幕大小\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "id": "4e0531cbc5adaad6",
   "metadata": {},
   "source": [
    "## 1.4、format()和invoke()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b6cec84b41227",
   "metadata": {},
   "source": [
    "- 调用format():  入参类型,给变量赋值的PromptTemplate; 返回值类型,格式化后(给变量赋值)的字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1174df680681a87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T01:39:32.782009Z",
     "start_time": "2025-11-05T01:39:32.768892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你叫阿智,是一个追求极致的AI应用开发工程师\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"你叫{name},是一个{personality}的{role}\")\n",
    "\n",
    "format_prompt = prompt_template.format(name=\"阿智\", personality=\"追求极致\", role=\"AI应用开发工程师\")\n",
    "print(format_prompt)\n",
    "print(type(format_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfbf3caca1093f2",
   "metadata": {},
   "source": [
    "- 调用invoke(): 入参类型为dict字典类型; 返回值类型为StringPromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8529ad964d3089f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T01:39:34.464958Z",
     "start_time": "2025-11-05T01:39:34.459559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='你叫小小智,是一个追求极致的AI应用开发工程师'\n",
      "<class 'langchain_core.prompt_values.StringPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"你叫{name},是一个{personality}的{role}\")\n",
    "\n",
    "invoke_prompt = prompt_template.invoke(input={\"name\":\"小小智\", \"personality\":\"追求极致\", \"role\":\"AI应用开发工程师\"})\n",
    "print(invoke_prompt)\n",
    "print(type(invoke_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab477917da5da6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.4、调用大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f9635a0b886b788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T01:39:48.773009Z",
     "start_time": "2025-11-05T01:39:42.913554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='好的，从生态和性能维度简单介绍LlamaIndex：\\n\\n**生态维度**\\nLlamaIndex拥有强大的数据连接能力，能无缝集成各类数据源、LLM和向量数据库，构建了一个繁荣的插件工具链生态，极大简化了数据接入与应用分发的流程。\\n\\n**性能维度**\\n它通过高效的索引结构、检索策略与查询引擎，在保证高精度检索的同时，显著提升了RAG应用的整体响应速度与吞吐量。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 24, 'total_tokens': 117, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 24}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'd3050e2d-4724-4a93-9cef-d04cb7d96b2d', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--fdd209c8-1a9e-4784-9166-eaa889a57b7f-0', usage_metadata={'input_tokens': 24, 'output_tokens': 93, 'total_tokens': 117, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chatModel = ChatOpenAI(\n",
    "    model = \"deepseek-chat\",\n",
    "    base_url = os.environ[\"BASE_URL\"],\n",
    "    api_key = os.environ[\"DEEPSEEK_API_KEY\"]\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"请在{aspect1}、{aspect2}等维度来简单介绍{product},要求每个维度用一两句话描述\")\n",
    "\n",
    "llm_prompt = prompt_template.format(aspect1=\"生态\",aspect2=\"性能\",product=\"LlamaIndex\")    # 类型为<class 'str'>\n",
    "# llm_prompt = prompt_template.invoke(input={\"aspect1\":\"生态\",\"aspect2\":\"性能\",\"product\":\"LlamaIndex\"})  # 类型为<class 'langchain_core.prompt_values.StringPromptValue'>\n",
    "\n",
    "print(type(llm_prompt))\n",
    "\n",
    "chatModel.invoke(llm_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f683d6fdc4d9e8d",
   "metadata": {},
   "source": [
    "# 2、ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059102b0ff37a5c",
   "metadata": {},
   "source": [
    "## 2.1、使用说明\n",
    "- ChatPromptTemplate是创建**聊天消息列表**的提示词模板,比PromptTemplate更适合处理多角色、多轮次的对话场景\n",
    "- 特点:\n",
    "  - 支持System、Human、AI等不同角色的消息模板,如果不指定角色,则默认是Human\n",
    "  - 维护对话历史\n",
    "- 参数类型:\n",
    "  - 列表参数为tuple类型,tuple每个元组对应一条结构化的对话消息模板,元组的两个元素 (role,content) 分别定义了消息的角色和消息的内容模板\n",
    "    - 格式为 (role:str|type,content:str|list[dict]|list[object])\n",
    "    - role可以是字符串(如:\"System\"、\"human\"、\"ai\"),也可以是消息类 类型(如:SystemMessage、HumanMessage、AIMessage)\n",
    "    - content可以是字符串、字典列表或对象列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a705f6ac017b9aa",
   "metadata": {},
   "source": [
    "## 2.2、ChatPromptTemplate的实例化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabca56c816907cc",
   "metadata": {},
   "source": [
    "- 1）使用构造方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81c05d9e21c9aff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T02:06:40.788884Z",
     "start_time": "2025-11-05T02:06:40.783243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: 你叫xuzhixing,是一名资深的AI应用开发工程师\n",
      "Human: 你会哪些技能?\n",
      "AI: 我熟悉RAG、Agent、大模型微调等多种主流AI技术\n",
      "Human: 请用两三句话介绍下RAG和Agent\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"你叫{name},是一名资深的{vocation}\"),\n",
    "        (\"human\", \"你会哪些技能?\"),\n",
    "        (\"ai\", \"我熟悉{skill}等多种主流AI技术\"),\n",
    "        (\"human\", \"请用两三句话介绍下{keyword}\")\n",
    "    ]\n",
    ")\n",
    "# chat_prompt = chat_prompt.invoke(input={\"name\":\"xuzhixing\",\"vocation\":\"AI应用开发工程师\",\"skill\":\"RAG、Agent、大模型微调\",\"keyword\":\"RAG和Agent\"})\n",
    "chat_prompt = chat_prompt.format(name=\"xuzhixing\",vocation=\"AI应用开发工程师\",skill=\"RAG、Agent、大模型微调\",keyword=\"RAG和Agent\")\n",
    "\n",
    "print(chat_prompt)\n",
    "print(type(chat_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e69b1988561ce",
   "metadata": {},
   "source": [
    "- 2）调用from_messages(): 可指定对话的角色和内容,角色有system、human、ai,如果不指定角色,则默认是human【用户】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce769990d7676ebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T02:12:53.519887Z",
     "start_time": "2025-11-05T02:12:53.508230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你叫xuzhixing,是一名资深的AI应用开发工程师', additional_kwargs={}, response_metadata={}), HumanMessage(content='你会哪些技能?', additional_kwargs={}, response_metadata={}), AIMessage(content='我熟悉RAG、Agent、大模型微调等多种主流AI技术', additional_kwargs={}, response_metadata={}), HumanMessage(content='请用两三句话介绍下RAG和Agent', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.prompt_values.ChatPromptValue'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你叫{name},是一名资深的{vocation}\"),\n",
    "        (\"human\", \"你会哪些技能?\"),\n",
    "        (\"ai\", \"我熟悉{skill}等多种主流AI技术\"),\n",
    "        (\"human\", \"请用两三句话介绍下{keyword}\")\n",
    "    ]\n",
    ")\n",
    "# chat_prompt = chat_prompt.invoke(input={\"name\":\"xuzhixing\",\"vocation\":\"AI应用开发工程师\",\"skill\":\"RAG、Agent、大模型微调\",\"keyword\":\"RAG和Agent\"})\n",
    "chat_prompt = chat_prompt.format(name=\"xuzhixing\",vocation=\"AI应用开发工程师\",skill=\"RAG、Agent、大模型微调\",keyword=\"RAG和Agent\")\n",
    "\n",
    "print(chat_prompt)\n",
    "print(type(chat_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229955de6901a3a",
   "metadata": {},
   "source": [
    "- 模板调用的函数:  invoke()、format()、format_messages()、format_prompt()\n",
    "- 给占位符赋值,针对ChatPromptTemplate,推荐使用from_messages()方法,返回消息列表\n",
    "- 创建ChatPromptTemplate时,不管是使用构造方法,还是使用from_messages(),参数是列表类型,列表中的元素可以是字符串、字典、字符串构成的元组、消息类型、提示词模板类型、消息提示词模板类型等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77ea164cd72c81",
   "metadata": {},
   "source": [
    "# 3、少量样本示例的提示词模板"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15632ae89418a9fa",
   "metadata": {},
   "source": [
    "## 3.1、使用说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e78d71ceb24f49",
   "metadata": {},
   "source": [
    "- FewShotPromptTemplate/FewShotChatMessagePromptTemplate:在构建Prompt时,可通过构建一个**少量示例列表**来格式化Prompt,简单且强大、稳定且可靠的指导回答生成【尽可能地减少幻觉】, 在某些情况下可以显著提高大模型的性能\n",
    "    - FewShotPromptTemplate:\n",
    "        - 输出内容为字符串,example_prompt属性为 PromptTemplate,不支持历史对话\n",
    "        - 适用场景: 文本补全模型、单次输入输出类任务、文本分类、摘要、代码生成、翻译等\n",
    "    - FewShotChatMessagePromptTemplate:用于聊天对话模式\n",
    "        - 输出内容为消息列表,example_prompt属性为 ChatPromptTemplate,支持历史对话\n",
    "        - 适用场景: 聊天对话模型、多轮对话交互、智能客服、情感分析、代码助手等\n",
    "- 少量示例提示模板可以由**一组示例** 或 一个负责从定义的集合中选择**一部分示例**的示例选择器构成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb85bb466f5b03e",
   "metadata": {},
   "source": "## 3.2、FewShotPromptTemplate"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "958b376e731115fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T05:45:56.116908Z",
     "start_time": "2025-11-05T05:45:52.616487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='长沙是湖南省的省会、地级市，其车牌代码为湘A' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 67, 'total_tokens': 83, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 3}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'e2856a3f-a3c2-4cea-a033-ed7fdd32758a', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--172f10c8-e093-4ba4-ad82-5440b04ccd17-0' usage_metadata={'input_tokens': 67, 'output_tokens': 16, 'total_tokens': 83, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}}\n",
      "content='宁波是浙江省的副省级市、计划单列市，其车牌代码为浙B。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 67, 'total_tokens': 87, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 3}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'f5b1a184-b813-4a7a-beb7-4a973b26922f', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--2525a7fd-df7c-4cc3-8ae5-948422a87aa8-0' usage_metadata={'input_tokens': 67, 'output_tokens': 20, 'total_tokens': 87, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}}\n",
      "长沙是湖南省的省会、地级市，其车牌代码为湘A\n",
      "宁波是浙江省的副省级市、计划单列市，其车牌代码为浙B。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# 1.创建示例集合\n",
    "few_shot = [\n",
    "    {\"question\": \"请介绍下深圳\", \"answer\": \"深圳是广东省的地级市,其车牌代码为粤B\"},\n",
    "    {\"question\": \"请介绍下武汉\", \"answer\": \"武汉是湖北省的省会、地级市,其车牌代码为鄂A\"}\n",
    "]\n",
    "\n",
    "# 2.创建PromptTemplate实例\n",
    "shot_prompt = PromptTemplate.from_template(\n",
    "    template=\"question: {question}\\nanswer: {answer}\"\n",
    ")\n",
    "\n",
    "# 3.创建FewShotPromptTemplate实例\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=few_shot,\n",
    "    example_prompt=shot_prompt,\n",
    "    suffix=\"question: {question}\\nanswer:\", # 要放在示例后面的提示模板字符串\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "# 4.调用大模型\n",
    "prompt1 = fewshot_prompt.format(question=\"请介绍下长沙\")\n",
    "response1 = chatModel.invoke(prompt1)\n",
    "print(response1)\n",
    "\n",
    "prompt2 = fewshot_prompt.format(question=\"请介绍下宁波\")\n",
    "response2 = chatModel.invoke(prompt2)\n",
    "print(response2)\n",
    "\n",
    "print(response1.content)\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc2487237a7a42",
   "metadata": {},
   "source": "## 3.3、FewShotChatMessagePromptTemplate"
  },
  {
   "cell_type": "markdown",
   "id": "e46447038f6208bc",
   "metadata": {},
   "source": [
    "- FewShotChatMessagePromptTemplate是专门为**聊天对话场景**设计的少样本(few-shot)提示模板,继承自FewShotPromptTemplate,并优化了聊天消息的格式\n",
    "- 特点:\n",
    "  - 自动将示例格式化为聊天消息(HumanMessage/AIMessage等)\n",
    "  - 输出结构化的聊天消息(List[BaseMessage])\n",
    "  - 保留对话的轮次结构"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 代码示例:",
   "id": "760d065c3e2f004b"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "818bcb7fb6f418ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T08:31:18.365877Z",
     "start_time": "2025-11-05T08:31:16.230932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入: 今天这顿饭真好吃！\n",
      "输出: 正向评价\n",
      "输入: 那个车还说得过去吧！\n",
      "输出: 中性评价\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# 1. 定义示例（每个示例包含输入和输出）\n",
    "few_shot = [\n",
    "    {\"input\": \"这部电影太棒了！\", \"output\": \"正向评价\"},\n",
    "    {\"input\": \"今天天气真糟糕。\", \"output\": \"负面评价\"},\n",
    "    {\"input\": \"这个产品还可以。\", \"output\": \"中性评价\"}\n",
    "]\n",
    "\n",
    "# 2. 创建示例格式化模板（必须使用 ChatPromptTemplate）\n",
    "shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])\n",
    "\n",
    "# 3. 创建 FewShotChatMessagePromptTemplate\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=few_shot,\n",
    "    example_prompt=shot_prompt,\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "# 4. 嵌入到 ChatPromptTemplate 中使用\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是评价分析助手。根据示例判断评价好坏\"),\n",
    "    few_shot_prompt,  # 自动插入 few-shot 示例\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "messages = final_prompt.format_messages(input=\"今天这顿饭真好吃！\")\n",
    "# 5. 调用对话模型\n",
    "response = chatModel.invoke(messages)\n",
    "print(f\"输入: 今天这顿饭真好吃！\")\n",
    "print(f\"输出: {response.content}\")\n",
    "\n",
    "\n",
    "messages = final_prompt.format_messages(input=\"那个车还说得过去吧！\")\n",
    "response = chatModel.invoke(messages)\n",
    "print(f\"输入: 那个车还说得过去吧！\")\n",
    "print(f\"输出: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588dfaf0",
   "metadata": {},
   "source": "## 3.4、Example selectors(示例选择器)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- FewShotPromptTemplate和FewShotChatMessagePromptTemplate的特点: 无论输入什么问题,都会包含全部示例\n",
    "- 在实际项目中,我们通常会根据当前输入, 使用示例选择器, 从大量候选示例中选取最相关的示例子集\n",
    "    - 使用的好处: 避免盲目传递所有示例, 降低噪音, 减少token消耗, 提升输出效果\n",
    "    - 示例选择策略: 语义相似选择、长度选择、最大边际相关示例选择等\n",
    "        - 语义相似选择: 通过余弦相似度、欧式距离等度量方式评估语义相关性, 选择和输入问题最相关的k个示例\n",
    "        - 长度选择: 根据输入文本的长度, 从候选示例中筛选出长度最匹配的示例, 增强模型对文本结构的理解, 比语义相似度计算更轻量, 适合对响应速度要求高的场景\n",
    "        - 优先选择 和 输入问题语义相似的示例, 同时通过惩罚机制来避免返回同质化的内容"
   ],
   "id": "27ca27e9894104e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 在如下的代码示例可分为 检索前处理和检索后处理\n",
    "    - 1）examples示例集中的问答示例 经由嵌入模型 转换为向量后,存储在Chroma库\n",
    "    - 2）对给定的问题通过嵌入模型生成向量,查询Chroma库 逐个比对&筛选, 得到最相关的2个示例"
   ],
   "id": "1ecf31e0f22fecf4"
  },
  {
   "cell_type": "code",
   "id": "df9131d49ac75f5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T09:00:10.977099Z",
     "start_time": "2025-11-05T09:00:07.674314Z"
    }
   },
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 1. 初始化嵌入模型\n",
    "embeddings_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# 2. 定义示例组（包含多个不同主题的问答示例）\n",
    "examples = [\n",
    "    {\"question\": \"Python是什么？\", \"answer\": \"Python是一种高级编程语言，以其简洁的语法和强大的功能而闻名。\"},\n",
    "    {\"question\": \"什么是机器学习？\", \"answer\": \"机器学习是人工智能的一个分支，让计算机通过数据学习而无需明确编程。\"},\n",
    "    {\"question\": \"如何学习编程？\", \"answer\": \"学习编程需要多实践、多写代码，可以从基础语法开始，逐步学习算法和项目开发。\"},\n",
    "    {\"question\": \"什么是深度学习？\", \"answer\": \"深度学习是机器学习的一个子领域，使用神经网络来模拟人脑的学习过程。\"},\n",
    "    {\"question\": \"LangChain是什么？\", \"answer\": \"LangChain是一个用于构建基于大语言模型应用的框架，提供了丰富的工具和组件。\"},\n",
    "    {\"question\": \"如何安装Python？\", \"answer\": \"可以从Python官网下载安装包，或使用Anaconda等发行版，安装后配置环境变量即可。\"},\n",
    "    {\"question\": \"什么是向量数据库？\", \"answer\": \"向量数据库是专门用于存储和检索高维向量数据的数据库，常用于相似度搜索。\"},\n",
    "    {\"question\": \"如何学习人工智能？\", \"answer\": \"学习AI需要掌握数学基础、编程技能，然后学习机器学习、深度学习等专业知识。\"},\n",
    "]\n",
    "\n",
    "# 3. 定义示例选择器\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 可供选择的示例列表\n",
    "    examples=examples,\n",
    "    # 指定生成向量的嵌入模型，用于衡量语义相似性\n",
    "    embeddings=embeddings_model,\n",
    "    # 存储嵌入并进行相似性搜索的 VectorStore 类\n",
    "    vectorstore_cls=Chroma,\n",
    "    # 指定生成的示例数量（选择最相似的k个示例）\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "# 4. 测试：不同问题会选择不同的相关示例（核心特点展示）\n",
    "print(\"=\" * 70)\n",
    "print(\"示例选择器核心特点:根据输入动态选择最相关的示例\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_questions = [\n",
    "    \"我想了解Python编程语言\",        # 应该选择\"Python是什么？\"相关示例\n",
    "    \"机器学习的基本概念是什么？\",      # 应该选择\"什么是机器学习？\"相关示例\n",
    "    \"如何开始学习编程？\",              # 应该选择\"如何学习编程？\"相关示例\n",
    "    \"什么是神经网络？\",                # 应该选择\"什么是深度学习？\"相关示例\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\n问题: {question}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # 选择与输入最相似的示例\n",
    "    selected_examples = example_selector.select_examples({\"question\": question})\n",
    "    \n",
    "    print(f\"选择的示例数量: {len(selected_examples)}\")\n",
    "    print(\"选择的示例:\")\n",
    "    \n",
    "    for i, example in enumerate(selected_examples, 1):\n",
    "        print(f\"\\n  示例 {i}:\")\n",
    "        for k, v in example.items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "    \n",
    "    print(\"-\" * 70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "示例选择器核心特点:根据输入动态选择最相关的示例\n",
      "======================================================================\n",
      "\n",
      "问题: 我想了解Python编程语言\n",
      "----------------------------------------------------------------------\n",
      "选择的示例数量: 2\n",
      "选择的示例:\n",
      "\n",
      "  示例 1:\n",
      "    question: Python是什么？\n",
      "    answer: Python是一种高级编程语言，以其简洁的语法和强大的功能而闻名。\n",
      "\n",
      "  示例 2:\n",
      "    question: 如何安装Python？\n",
      "    answer: 可以从Python官网下载安装包，或使用Anaconda等发行版，安装后配置环境变量即可。\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "问题: 机器学习的基本概念是什么？\n",
      "----------------------------------------------------------------------\n",
      "选择的示例数量: 2\n",
      "选择的示例:\n",
      "\n",
      "  示例 1:\n",
      "    answer: 机器学习是人工智能的一个分支，让计算机通过数据学习而无需明确编程。\n",
      "    question: 什么是机器学习？\n",
      "\n",
      "  示例 2:\n",
      "    question: 什么是深度学习？\n",
      "    answer: 深度学习是机器学习的一个子领域，使用神经网络来模拟人脑的学习过程。\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "问题: 如何开始学习编程？\n",
      "----------------------------------------------------------------------\n",
      "选择的示例数量: 2\n",
      "选择的示例:\n",
      "\n",
      "  示例 1:\n",
      "    question: 如何学习编程？\n",
      "    answer: 学习编程需要多实践、多写代码，可以从基础语法开始，逐步学习算法和项目开发。\n",
      "\n",
      "  示例 2:\n",
      "    answer: 学习AI需要掌握数学基础、编程技能，然后学习机器学习、深度学习等专业知识。\n",
      "    question: 如何学习人工智能？\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "问题: 什么是神经网络？\n",
      "----------------------------------------------------------------------\n",
      "选择的示例数量: 2\n",
      "选择的示例:\n",
      "\n",
      "  示例 1:\n",
      "    question: 什么是深度学习？\n",
      "    answer: 深度学习是机器学习的一个子领域，使用神经网络来模拟人脑的学习过程。\n",
      "\n",
      "  示例 2:\n",
      "    answer: 机器学习是人工智能的一个分支，让计算机通过数据学习而无需明确编程。\n",
      "    question: 什么是机器学习？\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 83
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
