# 1、什么是LangChain
- LangChain: 专为快速构建复杂的大语言模型应用而设计的开源框架,通过模块化组件(Agents、Memory、Tools等)和预制工具链,解决了传统LLM开发中的三大痛点:
    - 1）上下文管理/对话记忆: 通过Memory组件(对话历史缓存、实体关系)实现长对话的连贯性
    - 2）多工具协同: 支持动态调用外部API、数据库、搜索引擎等工具
    - 3）复杂任务编排: 通过Chains链和Agent(代理),将多个LLM调用和工具操作组合成工具流,如:
      - 用户输入 => 清洗数据 => 调用大模型 =》结构化输出
      - 电商场景: 用户问“如何退货”,则流程可能是: 理解问题 => 查询退货政策 => 生成回复 => 记录工单
- LangChain应用场景: 搭建智能体(Agent)、智能客服(ConversationChain+RAG+Agent)、文档问答助手(Prompt+Embedding+RetrievalQA)、企业私有知识库(RAG+本地模型)、多模型路由对话系统(RouterChain+多LLM)等
- LangChain集成和内置了很多开发AI大模型应用所需的技术(如:文档加载器、文档拆分器、文档嵌入、向量数据库、提示词构建、工具调用、对话记忆、HTTP API封装、云服务适配器、RAG等),将大语言模型和各种工具及数据源连接起来,形成一个""链式"结构,
让开发者开箱急用

# 2、为什么需要LangChain
## 1) LLMs用的挺好,还需要LangChain?
- 大模型存在训练数据时效性差、输出回答不稳定、无法对接外部工具、无法接入企业私有数据、无法查询数据库、无法连接互联网、不能调用第三方API等问题,而LangChain可解决这些问题
- 开发者不仅希望能"使用"ChatGPT、Claude、DeepSeek等大模型,还需要将其灵活集成到AI应用中,实现更强大的对话能力、检索增强生成(RAG)、工具调用(Tool Calling)、推理和完成复杂任务等功能

## 2）为什么不用GPT等大模型的API开发,而选择LangChain？
- 不使用LangChain，确实可以使用GPT 或GLM4 等模型的API进行开发。比如，搭建“智能体” (Agent)、问答系统、对话机器人等复杂的 LLM 应用
- 但使用LangChain的好处在于:
  - 简化开发难度: 提供标准化的接口和模板,更简单、更高效、实现效果更好
  - 学习成本更低: 不同模型的API不同,调用方式也有区别,切换模型时学习成本高;使用LangChain,通过统一、规范的方式来调用,有更好的移植性
  - 现成的链式组装: LangChain提供了一些现成的链式组装,用于完成特定的高级任务,让复杂的逻辑变得结构化、易组合、易扩展
  - 省钱省时: 通过缓存、批处理等技术优化性能,降低大模型的调用成本

# 3、LangChain核心组件
LangChain核心组件包括:
- 1) Models(模型): 支持多种大语言模型,如: OpenAI、Anthropic、Llama等,提供统一的接口,便于在不同模型之间切换
- 2) Prompt Template(提示词模板): 允许用户创建动态提示词,提高模型的泛化能力,通过模板化的方式,可根据不同的输入 生成相应的提示词,从而引导模板生成更准确的输出
- 3) Memory(记忆): 用于存储对话的上下文信息,支持短期记忆(常用于当前会话的上下文) 和 长期记忆(结合向量数据库,持久化重要信息)
      LangChain能够在多轮对话中保持上下文的一致性,提升了对话的连贯性和智能性
- 4) Chains(链式调用): 串联多个处理步骤,形成一个处理流程【将复杂任务拆解为多个子任务,并通过链式调用的方式依次处理】,
      支持Simple Chains(单步骤任务) 和 Sequential Chains(多步骤任务),使复杂任务的处理更加模块化和可复用
- 5) Agents(智能体): 通过ReAct,Agent可根据用户的输入 动态选择合适的工具来完成任务,实现更灵活的任务处理
- 6) Tools(工具): 集成各种外部工具,提供访问外部资源的能力,如: 外部API、Google搜索、数据库查询等,扩展了大模型的功能,使其能够处理更加复杂的任务

# 4、LangChain核心架构是怎样的
- LangChain的核心架构由四大关键模块组成: LangChain Libraries、LangChain Templates、LangServe 和 LangSmith,各自承担不同的角色,共同组建了一个完整的LLM应用开发、部署和监控的闭环体系
- 1) LangChain Libraries: 整个框架的基础,包含多个子模块
    - langchain-core: LangChain的基础库,提供构建应用所需的核心功能,如:模型接口和消息类型的定义、会话记忆、提示词模板、工具、输出解析器等,设计轻量,便于扩展
    - langchain: 构建链(Chains) 和 代理(Agents)的主要模块,处理复杂的业务逻辑和外部API交互
    - langchain-community: 整合/集成社区贡献的第三方工具,如:文件加载器、向量数据库等
- 2) LangChain Templates: 提供一系列易于部署的参考架构,适用于各种任务,便于快速上手和定制
- 3) LangServe: 用于将LangChain构建的链 部署为Rest API的库,集成了FastAPI,支持流式、批量处理等功能,方便将应用推向生产环境
- 4) LangSmith: 开发者平台,提供调试、测试、评估和监控功能,帮助开发者优化和部署基于LangChain构建的应用

# 5、什么是LangChain Model
- LangChain中的Model模块,主要是为了解决和各种大语言模型(LLM)打交道时的统一接口问题,提供了一套标准化的方式,让开发者可以用同样的方式调用 OpenAI、Hugging Face、Anthropic等不同厂商的大模型,
像是给不同品牌的家电配上了通用的插头,而开发者不需要为每个品牌单独准备一个插座
- LangChain的Model模块包含如下部分:
    - 1) LLM 和 ChatModel接口: 
        - LLM接口适用于传统的文本输入输出模型(输入输出都是字符串)
        - ChatModel接口则专为对话式模型设计,输入和输出均为消息格式(如:SystemMessage、UserMessage、AIMessage),支持多轮对话和上下文管理,适用于构建聊天机器人等应用
    - 2) Prompt模板: 可灵活地构建和管理提示词,支持变量替换、条件逻辑等功能,方便生成动态的输入内容
    - 3) 输出解析器(Output Parsers): 用于将大模型的原始输出转换为JSON、CSV等结构化的数据格式,方便后续处理
    - 4) 支持同步和异步: 无论是需要同步调用 还是异步处理,LangChain都提供了相应的支持,以满足不同的应用场景需求;异步支持 适用于需要高并发处理的场景
    - 5) 批量处理和流式输出: 批量处理适用于一次性处理多个输入,提高效率; 流式输出则允许开发者 在回答生成过程中实时获取输出,提升处理效率和用户体验

# 6、什么是LangChain Agent
- LangChain Agent是LangChain中的核心组件,基于大模型的推理能力,根据用户的输入动态地选择并调用合适的工具(Tools) 或 链(Chain),以完成复杂的任务
- 与传统的链式调用不同,Agent不依赖于预定义的流程,而是根据实际情况灵活地决策和执行操作
即Agent是智能指挥官(大脑),接收用户的指令后,分析任务需求 => 制定执行计划 => 选择合适的工具或方法 =》根据执行结果进行调整 =》迭代操作,直至完成任务