{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7385e8fe0442726b",
   "metadata": {},
   "source": [
    "# 对话模型的消息(Message)\n",
    "- SystemMessage: 系统提示词,指定大模型的行为规则 或 背景信息,如: 设定初始状态、行为模式 或 对话的目标对象\n",
    "- HumanMessage: 用户查询问题\n",
    "- AIMessage: 存储AI回复的内容,可以是文本 或 调用工具的请求\n",
    "上面三个Message最为常用\n",
    "- FunctionMessage/ToolMessage: 函数调用/工具调用的消息，用于表示调用结果的消息类型\n",
    "- ChatMessage: 可自定义角色的通用消息类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee7db906f5ee999",
   "metadata": {},
   "source": [
    "代码示例1:"
   ]
  },
  {
   "cell_type": "code",
   "id": "cede4ba47075cb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:54:43.192880Z",
     "start_time": "2025-11-04T23:54:43.028449Z"
    }
   },
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "systemMessage = SystemMessage(\n",
    "    content= \"你是一名精通各种编程语言的专家\",\n",
    "    additional_kwargs = {\"current_time\": current_time, \"role_type\": \"program\"})\n",
    "\n",
    "humanMessage = HumanMessage(content= \"你是一名资深的AI应用开发专家\")\n",
    "aiMessage = AIMessage(content= \"你是一名擅长情感分析的恋爱专家\")\n",
    "\n",
    "custom_message = ChatMessage(\n",
    "    role=\"assistant\",\n",
    "    content=\"你是一名乐于助人的客服助手\"\n",
    ")\n",
    "# ChatMessage 的 role 参数详解：\n",
    "# role 参数用于指定消息的角色，通常有以下几个标准值：\n",
    "# - \"system\": 系统消息，等同于 SystemMessage\n",
    "# - \"user\" 或 \"human\": 用户消息，等同于 HumanMessage\n",
    "# - \"assistant\" 或 \"ai\": AI回复消息，等同于 AIMessage\n",
    "# - 自定义角色名：如 \"assistant_v2\", \"expert\" 等（某些模型支持）\n",
    "\n",
    "messages = [systemMessage, humanMessage, aiMessage, custom_message]\n",
    "print(f\"messages: {messages}\")\n",
    "print(\"=======\")\n",
    "print(systemMessage.content)\n",
    "print(humanMessage.content)\n",
    "print(aiMessage.content)\n",
    "print(custom_message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages: [SystemMessage(content='你是一名精通各种编程语言的专家', additional_kwargs={'current_time': '2025-11-05 07-54-43', 'role_type': 'program'}, response_metadata={}), HumanMessage(content='你是一名资深的AI应用开发专家', additional_kwargs={}, response_metadata={}), AIMessage(content='你是一名擅长情感分析的恋爱专家', additional_kwargs={}, response_metadata={}), ChatMessage(content='你是一名乐于助人的客服助手', additional_kwargs={}, response_metadata={}, role='assistant')]\n",
      "=======\n",
      "你是一名精通各种编程语言的专家\n",
      "你是一名资深的AI应用开发专家\n",
      "你是一名擅长情感分析的恋爱专家\n",
      "你是一名乐于助人的客服助手\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "代码示例2: 使用Message完成角色设定 并调用大模型",
   "id": "e1a0168cd907e8ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T01:00:43.734424Z",
     "start_time": "2025-11-04T01:00:15.349914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chatModel = ChatOpenAI(\n",
    "    model = \"deepseek-chat\",\n",
    "    base_url = os.environ[\"BASE_URL\"],\n",
    "    api_key = os.environ[\"DEEPSEEK_API_KEY\"]\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一名AI领域的专家\"),\n",
    "    HumanMessage(content=\"请你通俗易懂的语言简单介绍下Transformer模型\")\n",
    "]\n",
    "response = chatModel.invoke(messages)\n",
    "print(f\"response: {response}\")\n",
    "print(f\"content: {response.content}\")\n",
    "print(f\"content type: {type(response.content)}\")"
   ],
   "id": "9828ff6b7055f4f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: content='好的，没问题！咱们用一个简单的比喻来解释一下 Transformer 模型。\\n\\n你可以把它想象成一个**超级高效的国际翻译团队**。\\n\\n**1. 传统翻译的瓶颈 (老方法的问题)**\\n\\n以前的方法（比如 RNN）就像是一个人在做翻译。他必须一个词一个词地看，看完整个句子才能开始翻译。这很慢，而且如果他看到句子后面，可能就忘了前面说的是什么了。\\n\\n**2. Transformer 的聪明做法 (核心思想)**\\n\\nTransformer 这个团队就不一样了，它做了两件非常聪明的事：\\n\\n*   **第一件事：大家一起上，同时看整个句子。**\\n    这个团队里的每个成员（在模型里叫“注意力头”）不需要按顺序读词。他们可以一瞬间就看到句子的所有部分。这样，他们就能立刻抓住重点，比如：\\n    *   “这个词‘它’指的是前面提到的哪个名词？”\\n    *   “这个形容词‘红色的’是形容哪个东西的？”\\n    这种能力就叫做 **“自注意力机制”**。它能帮模型理解句子中每个词和其他所有词之间的关系。\\n\\n*   **第二件事：分工合作，理解不同层面的信息。**\\n    这个团队内部还有分工：\\n    *   有的人专门负责分析**语法结构**（比如主谓宾）。\\n    *   有的人专门负责理解**词义和上下文**（比如“苹果”是指水果还是公司）。\\n    *   有的人专门负责把握**整体情感和风格**（是正式的还是口语的）。\\n    通过这种分工，团队对句子的理解就非常全面和深刻。\\n\\n**总结一下 Transformer 的工作流程：**\\n\\n1.  **输入句子**：把一句话（比如中文）交给这个团队。\\n2.  **全面理解**：团队成员利用“自注意力”同时分析句子，搞懂每个词的意思和它们之间的关系。\\n3.  **分工协作**：不同专家从不同角度深入理解句子含义。\\n4.  **输出结果**：基于深刻的理解，团队协作生成最合适的翻译结果（比如英文）。\\n\\n**它为什么这么厉害？**\\n\\n*   **速度快**：因为可以并行处理所有词，而不是一个一个来，所以训练速度极快。\\n*   **理解深**：自注意力机制让它能真正理解上下文，处理长句子和复杂关系的能力非常强。\\n\\n**不只是翻译：**\\n\\n现在你明白了，这个“翻译团队”的能力其实非常通用。所以，Transformer 现在已经成为了当今最强大AI模型（比如 ChatGPT、BERT 等）的核心技术，被广泛用于：\\n*   **聊天机器人**（理解你的问题并生成回答）\\n*   **文章总结和写作**\\n*   **写代码**\\n*   **图片生成**（比如根据文字描述生成图片）\\n\\n简单来说，**Transformer 就是一个能同时关注所有信息，并深刻理解其内在联系的超级大脑**。它彻底改变了我们处理语言和其他序列数据的方式。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 594, 'prompt_tokens': 18, 'total_tokens': 612, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 18}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '07158aa0-7cab-4e56-aecf-756320398075', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--467f100b-cf51-4dd8-917d-f88837df0b74-0' usage_metadata={'input_tokens': 18, 'output_tokens': 594, 'total_tokens': 612, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "content: 好的，没问题！咱们用一个简单的比喻来解释一下 Transformer 模型。\n",
      "\n",
      "你可以把它想象成一个**超级高效的国际翻译团队**。\n",
      "\n",
      "**1. 传统翻译的瓶颈 (老方法的问题)**\n",
      "\n",
      "以前的方法（比如 RNN）就像是一个人在做翻译。他必须一个词一个词地看，看完整个句子才能开始翻译。这很慢，而且如果他看到句子后面，可能就忘了前面说的是什么了。\n",
      "\n",
      "**2. Transformer 的聪明做法 (核心思想)**\n",
      "\n",
      "Transformer 这个团队就不一样了，它做了两件非常聪明的事：\n",
      "\n",
      "*   **第一件事：大家一起上，同时看整个句子。**\n",
      "    这个团队里的每个成员（在模型里叫“注意力头”）不需要按顺序读词。他们可以一瞬间就看到句子的所有部分。这样，他们就能立刻抓住重点，比如：\n",
      "    *   “这个词‘它’指的是前面提到的哪个名词？”\n",
      "    *   “这个形容词‘红色的’是形容哪个东西的？”\n",
      "    这种能力就叫做 **“自注意力机制”**。它能帮模型理解句子中每个词和其他所有词之间的关系。\n",
      "\n",
      "*   **第二件事：分工合作，理解不同层面的信息。**\n",
      "    这个团队内部还有分工：\n",
      "    *   有的人专门负责分析**语法结构**（比如主谓宾）。\n",
      "    *   有的人专门负责理解**词义和上下文**（比如“苹果”是指水果还是公司）。\n",
      "    *   有的人专门负责把握**整体情感和风格**（是正式的还是口语的）。\n",
      "    通过这种分工，团队对句子的理解就非常全面和深刻。\n",
      "\n",
      "**总结一下 Transformer 的工作流程：**\n",
      "\n",
      "1.  **输入句子**：把一句话（比如中文）交给这个团队。\n",
      "2.  **全面理解**：团队成员利用“自注意力”同时分析句子，搞懂每个词的意思和它们之间的关系。\n",
      "3.  **分工协作**：不同专家从不同角度深入理解句子含义。\n",
      "4.  **输出结果**：基于深刻的理解，团队协作生成最合适的翻译结果（比如英文）。\n",
      "\n",
      "**它为什么这么厉害？**\n",
      "\n",
      "*   **速度快**：因为可以并行处理所有词，而不是一个一个来，所以训练速度极快。\n",
      "*   **理解深**：自注意力机制让它能真正理解上下文，处理长句子和复杂关系的能力非常强。\n",
      "\n",
      "**不只是翻译：**\n",
      "\n",
      "现在你明白了，这个“翻译团队”的能力其实非常通用。所以，Transformer 现在已经成为了当今最强大AI模型（比如 ChatGPT、BERT 等）的核心技术，被广泛用于：\n",
      "*   **聊天机器人**（理解你的问题并生成回答）\n",
      "*   **文章总结和写作**\n",
      "*   **写代码**\n",
      "*   **图片生成**（比如根据文字描述生成图片）\n",
      "\n",
      "简单来说，**Transformer 就是一个能同时关注所有信息，并深刻理解其内在联系的超级大脑**。它彻底改变了我们处理语言和其他序列数据的方式。\n",
      "content type: <class 'str'>\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
