{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4f0add7b3e98583c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型调用的方式",
   "id": "a6d75c0d5c2d6d72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.非流式和流式输出",
   "id": "5c5ca35e7f219c0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 提前引入大模型:",
   "id": "f6c68fb89503b034"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T09:11:45.867963Z",
     "start_time": "2025-11-06T09:11:43.735878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model = \"deepseek-chat\",\n",
    "    base_url = os.environ[\"BASE_URL\"],\n",
    "    api_key = os.environ[\"DEEPSEEK_API_KEY\"]\n",
    ")"
   ],
   "id": "8bd0ef6e7e6ed880",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- invoke阻塞式调用(非流式输出):\n",
    "1) 用户发出提问请求后, 后台会等待大模型 生成完整响应,一次性将结果全部返回\n",
    "2) LLM和大模型交互时的默认方式, 简单且稳定\n",
    "3) 适用于大多数问答、摘要、信息抽取类任务,可快速集成和部署"
   ],
   "id": "bb579f5b8bb94f6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:53:26.652700Z",
     "start_time": "2025-11-04T23:53:23.338548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Must be a PromptValue, str, or list of BaseMessages\n",
    "# 即提示词必须是PromptValue,字符串 或 Message列表\n",
    "messages = [\n",
    "    HumanMessage(\"请用两三句话简单介绍下LangChain\")\n",
    "]\n",
    "## invoke阻塞式调用\n",
    "response = chat_model.invoke(messages)\n",
    "\n",
    "print(f\"response: {response}\")\n",
    "print(f\"response type: {type(response)}\")\n",
    "print(f\"content type: {type(response.content)}\")"
   ],
   "id": "31ba539aaee44e11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: content='LangChain是一个用于开发大语言模型应用的框架。它通过提供模块化组件和链式调用，简化了与外部数据源和工具的集成过程。开发者可以利用它快速构建基于大语言模型的端到端应用，如问答系统和智能代理。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 13, 'total_tokens': 66, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 13}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'f2903ad8-3886-49e4-9a1e-e1c6af125239', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--53871be3-1dfb-474e-95df-2d6d8d3ff8ee-0' usage_metadata={'input_tokens': 13, 'output_tokens': 53, 'total_tokens': 66, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "response type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "content type: <class 'str'>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- stream流式调用:\n",
    "1) 更具交互感的输出方式, 用户不用等待完整回答, 可看到大模型逐个token 实时地返回内容\n",
    "2) 初始化ChatModel时,设置 streaming=True 并配合 回调机制 来启用流式输出\n",
    "3) 适合构建强调“实时反馈”的应用，如聊天机器人、写作助手等"
   ],
   "id": "5c93d62f6dee2623"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:53:58.553321Z",
     "start_time": "2025-11-04T23:53:29.108340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# invoke阻塞式调用\n",
    "stream_chat_model = ChatOpenAI(\n",
    "    model = \"deepseek-chat\",\n",
    "    base_url = os.environ[\"BASE_URL\"],\n",
    "    api_key = os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "    streaming=True # 开启流式输出\n",
    ")\n",
    "\n",
    "messages2 = [\n",
    "    HumanMessage(\"请简单介绍下LangChain\")\n",
    "]\n",
    "print(\"开始流式输出回答:\\n\")\n",
    "for chunk in stream_chat_model.stream(messages2):\n",
    "    # 刷新缓冲区 (无换行符，缓冲区未刷新，内容可能不会立即显示)\n",
    "    print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "print(\"/n流式输出结束\")"
   ],
   "id": "77f7473ef899d129",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始流式输出回答:\n",
      "\n",
      "好的，这是一个对LangChain的简单介绍。\n",
      "\n",
      "### 什么是LangChain？\n",
      "\n",
      "**LangChain** 是一个用于开发由大型语言模型驱动的应用程序的**框架**。你可以把它想象成一个“工具箱”或“脚手架”，它的核心目的是让开发者能够更轻松、更高效地将LLM（如GPT系列、LLaMA等）与外部数据源和计算能力连接起来，从而构建出功能强大且实用的应用。\n",
      "\n",
      "简单来说，LangChain解决了LLM原生存在的几个主要问题：\n",
      "1.  **信息陈旧**：LLM的训练数据有截止日期，不知道最新信息。\n",
      "2.  **缺乏上下文**：LLM无法直接访问你私有的、特定领域的数据（如公司文档、个人笔记）。\n",
      "3.  **“幻觉”问题**：LLM有时会编造看似合理但实际错误的信息。\n",
      "4.  **无法执行动作**：LLM本身不能替你做事情，比如发邮件、查询数据库。\n",
      "\n",
      "### 核心思想：链\n",
      "\n",
      "LangChain的名字就来源于其核心思想——**“链”**。它通过将不同的组件像链条一样连接起来，完成复杂的任务。一个典型的链条可能包括：\n",
      "1.  接收用户输入。\n",
      "2.  用一个提示模板格式化输入。\n",
      "3.  将格式化后的提示传递给LLM。\n",
      "4.  将LLM的输出解析为结构化数据。\n",
      "5.  根据这个数据去执行一个动作（如查询数据库、调用API）。\n",
      "\n",
      "### 核心组件\n",
      "\n",
      "为了让“链”能够工作，LangChain提供了几个关键组件：\n",
      "\n",
      "1.  **模型**：支持多种LLM和聊天模型（如OpenAI, Anthropic, 开源模型等）以及嵌入模型。\n",
      "2.  **提示**：管理LLM的输入。包括**提示模板**（可复用的提示结构）和**示例选择器**（为提示动态选择最佳示例）。\n",
      "3.  **链**：将多个组件组合在一起，形成一个完整的工作流。这是LangChain的核心。\n",
      "4.  **检索器**：用于从外部数据源（如文档、数据库）中获取相关数据，是解决“信息陈旧”和“缺乏上下文”的关键。\n",
      "5.  **代理**：这是更高级的“链”。代理可以理解用户指令，然后**自主地决定使用哪些工具**来完成任务。工具可以是搜索引擎、计算器、API等。代理让LLM从“聊天机器人”变成了可以“行动”的智能体。\n",
      "6.  **记忆**：为对话或交互提供记忆能力，使其能够记住之前说过的话，实现多轮对话的上下文连贯。\n",
      "\n",
      "### 一个简单的比喻\n",
      "\n",
      "你可以把LangChain想象成一个**高级的乐高套装**：\n",
      "*   **单个的LLM**就像是一堆积木块，潜力巨大，但需要你自己设计和搭建。\n",
      "*   **LangChain**则提供了预先设计好的**齿轮、轴、马达和说明书**。\n",
      "*   使用LangChain，你可以更快、更可靠地搭建出复杂的机械（比如一个能回答问题、能查资料、能自动写报告的机器人），而不需要从零开始研究每一块积木该怎么放。\n",
      "\n",
      "### 它能用来做什么？\n",
      "\n",
      "*   **构建特定领域的问答机器人**：基于公司内部文档、技术手册、法律条文等构建智能客服或知识库系统。\n",
      "*   **聊天机器人**：构建具有记忆和上下文理解能力的复杂对话系统。\n",
      "*   **智能代理**：构建可以自主完成任务的AI助手，例如“帮我分析一下最近的销售数据，并写一份总结报告发到我的邮箱”。\n",
      "*   **文档总结与分析**：快速分析和总结长文档、多篇报道的核心内容。\n",
      "\n",
      "### 总结\n",
      "\n",
      "总而言之，LangChain不是一个模型，而是一个**框架**。它通过“链”和“代理”等概念，将大型语言模型与外部世界连接起来，极大地扩展了LLM的能力边界，让开发者能够构建出真正智能和实用的下一代应用程序。/n流式输出结束\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.批量调用",
   "id": "7b3c23f81fd58267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- batch批量调用: 一次性将多个对话传个大模型, 让大模型批量生成回答",
   "id": "a8d35df3d092247b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:54:05.821222Z",
     "start_time": "2025-11-04T23:54:01.824792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "messages1 = [\n",
    "    SystemMessage(content=\"你是一位人工智能应用领域的专家\"),\n",
    "    HumanMessage(content=\"请用两三句话简单介绍下什么是机器学习\")\n",
    "]\n",
    "\n",
    "messages2 = [\n",
    "    SystemMessage(content=\"你是一位资深的Java+AI应用开发方向的工程师\"),\n",
    "    HumanMessage(content=\"请用两三句话简单介绍下现在企业中的主流技术栈都有哪些\")]\n",
    "\n",
    "messages3 = [\n",
    "    SystemMessage(content=\"你是一位乐于助人的智能小助手\"),\n",
    "    HumanMessage(content=\"请用两三句话简单介绍下什么是大模型技术\")]\n",
    "\n",
    "msg_list = [messages1, messages2, messages3]\n",
    "response = chat_model.batch(msg_list)\n",
    "\n",
    "print(f\"response: {response}\")\n",
    "print(f\"response type: {type(response)}\")"
   ],
   "id": "ec83b18e1b15e914",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: [AIMessage(content='机器学习是人工智能的一个分支，它让计算机通过分析数据来自动学习和改进，而无需显式编程。其核心在于从历史数据中识别模式，并利用这些模式来预测未来或做出决策。常见的应用包括推荐系统、图像识别和自然语言处理等。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 19, 'total_tokens': 77, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 19}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': 'e45fbb4b-4749-4fb7-9f6c-ed456db26927', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a03a286d-e38b-4214-af18-2e9491082924-0', usage_metadata={'input_tokens': 19, 'output_tokens': 58, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), AIMessage(content='目前企业中主流的技术栈主要包括Spring Boot、Spring Cloud等微服务框架，结合MySQL、Redis等数据库与缓存系统。前端通常采用Vue、React等框架，并通过Docker、Kubernetes实现容器化部署。同时，大数据与AI场景下常集成Hadoop、Spark、TensorFlow等组件。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 30, 'total_tokens': 97, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 30}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '86ac8234-702b-4a06-9a02-cb740e53dfe2', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a4428606-1f58-4c0b-9e77-d9e45026952b-0', usage_metadata={'input_tokens': 30, 'output_tokens': 67, 'total_tokens': 97, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}), AIMessage(content='大模型技术是指基于海量数据训练、拥有庞大参数规模（通常达数十亿甚至万亿级别）的深度学习模型。这类模型能够通过预训练学习通用知识和语言规律，并借助微调适配多种下游任务，例如文本生成、对话系统和代码编写。其核心突破在于通过扩大模型参数和数据规模，显著提升了人工智能的泛化与推理能力。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 23, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 23}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_ffc7281d48_prod0820_fp8_kvcache', 'id': '94e18648-3b18-4a30-93bb-af907d281cb0', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--868312f3-deec-41db-8a36-9d7863eb6f48-0', usage_metadata={'input_tokens': 23, 'output_tokens': 78, 'total_tokens': 101, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})]\n",
      "response type: <class 'list'>\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.同步调用和异步调用",
   "id": "b83b7fcb60ad52b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 同步调用: 每个操作依次执行,直到当前操作完成后才开始下一个操作,其总执行耗时是各个操作的时间总和",
   "id": "8e25a8204da6eb4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T09:12:07.210724Z",
     "start_time": "2025-11-06T09:12:00.199626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def call_model():\n",
    "    print(\"开始调用大模型...\")\n",
    "    time.sleep(2)  # 模拟调用过程,等待两秒\n",
    "    print(\"大模型调用结束\")\n",
    "\n",
    "def invoke_other_task():\n",
    "    for i in range(5):\n",
    "        print(f\"执行其他任务{i+1}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "def sync_main():\n",
    "    start_time = time.time()\n",
    "    call_model()\n",
    "    invoke_other_task()\n",
    "    end_time = time.time()\n",
    "    cost_time = end_time - start_time\n",
    "    return f\"all invoke cost time: {cost_time}\"\n",
    "\n",
    "time_info = sync_main()\n",
    "print(time_info)"
   ],
   "id": "89fb45dbb65da44a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始调用大模型...\n",
      "大模型调用结束\n",
      "执行其他任务1\n",
      "执行其他任务2\n",
      "执行其他任务3\n",
      "执行其他任务4\n",
      "执行其他任务5\n",
      "all invoke cost time: 7.005067825317383\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 异步调用: 允许程序在等待某些操作完成时,继续执行其他任务,而不是阻塞等待;\n",
    "    适用于处理I/O操作(如网络请求、文件读写等),可显著提高程序的执行效率和响应速度"
   ],
   "id": "b064c824a308f838"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T09:12:14.420467Z",
     "start_time": "2025-11-06T09:12:09.401869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def async_call(llm):\n",
    "    await asyncio.sleep(5) # 模拟异步操作\n",
    "    print(\"异步调用完成\")\n",
    "\n",
    "async def perform_other_tasks():\n",
    "    await asyncio.sleep(5) # 模拟异步操作\n",
    "    print(\"其他任务完成\")\n",
    "\n",
    "async def run_async_tasks():\n",
    "    start_time = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_call(None), # 示例调用，使用None模拟LLM对象\n",
    "        perform_other_tasks()\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    return f\"总共耗时：{end_time - start_time}秒\"\n",
    "\n",
    "# # 正确运行异步任务的方式\n",
    "# if __name__ == \"__main__\":\n",
    "# # 使用 asyncio.run() 来启动异步函数\n",
    "# result = asyncio.run(run_async_tasks())\n",
    "# print(result)\n",
    "\n",
    "# 在 Jupyter 单元格中直接调用\n",
    "result = await run_async_tasks()\n",
    "print(result)"
   ],
   "id": "710eebc922650273",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "异步调用完成\n",
      "其他任务完成\n",
      "总共耗时：5.0139172077178955秒\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- ainvoke异步调用验证:",
   "id": "5ab00a4d2aa6e65b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T09:12:15.847185Z",
     "start_time": "2025-11-06T09:12:15.844238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import inspect\n",
    "\n",
    "print(\"ainvoke 是协程函数【是否异步】:\", inspect.iscoroutinefunction(chat_model.ainvoke))\n",
    "print(\"invoke 是协程函数【是否异步】:\", inspect.iscoroutinefunction(chat_model.invoke))"
   ],
   "id": "26fcba4c6c10c35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ainvoke 是协程函数【是否异步】: True\n",
      "invoke 是协程函数【是否异步】: False\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
