{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3721b2c6ba9b7",
   "metadata": {},
   "source": [
    "# 一、LangChain文档加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c75d17149543c9",
   "metadata": {},
   "source": [
    "- LangChain的设计：对于 Source 中多种不同的数据源，我们可以用一种统一的形式读取、调用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc475ae818678a",
   "metadata": {},
   "source": [
    "## 1、TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d136c482516d0",
   "metadata": {},
   "source": [
    "- TextLoader是 LangChain 中最基础的文档加载器,用于加载纯文本文件\n",
    "- TextLoader的主要功能:\n",
    "    - 读取本地文本文件,支持指定字符编码（UTF-8、GBK等）\n",
    "    - 将文本内容转换为 Document 对象,自动提取文件元数据信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094cc394df658d4",
   "metadata": {},
   "source": [
    "### 1.1、基础使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e50c4730751862c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:02:29.380136Z",
     "start_time": "2025-11-11T01:02:29.371789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs len: 1\n",
      "docs type: <class 'langchain_core.documents.base.Document'>\n",
      "docs metadata: {'source': './document/load/01-langchain-utf-8.txt'}\n",
      "docs page_content: LangChain 框架核心介绍\n",
      "\n",
      "一、什么是 LangChain\n",
      "\n",
      "LangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。\n",
      "\n",
      "它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务。\n",
      "\n",
      "二、核心特性\n",
      "\n",
      "1. 模块化设计\n",
      "LangChain 采用模块化架构，开发者可以根据需求选择和使用不同的组件。主要模块包括：\n",
      "- 文档加载器（Document Loaders）：支持从各种数据源加载文档\n",
      "- 文本分割器（Text Splitters）：将长文本分割成适合处理的块\n",
      "- 向量存储（Vector Stores）：存储和检索文档的向量表示\n",
      "- 链（Chains）：将多个组件串联起来执行复杂任务\n",
      "- 代理（Agents）：让 LLM 能够自主决策和调用工具\n",
      "- 记忆（Memory）：管理对话历史和上下文信息\n",
      "\n",
      "2. 丰富的集成能力\n",
      "LangChain 支持与多种 LLM 提供商集成，包括：\n",
      "- OpenAI GPT 系列模型\n",
      "- 开源模型（如 Llama、Mistral 等）\n",
      "- 本地部署的模型\n",
      "\n",
      "3. 强大的文档处理能力\n",
      "通过 TextLoader 等文档加载器，LangChain 可以：\n",
      "- 加载各种格式的文档（TXT、PDF、HTML、Markdown 等）\n",
      "- 处理不同编码的文本文件（UTF-8、GBK 等）\n",
      "- 提取文档的元数据信息\n",
      "- 将文档转换为标准化的 Document 对象\n",
      "\n",
      "三、TextLoader 的作用\n",
      "\n",
      "TextLoader 是 LangChain 中最基础的文档加载器之一，它的主要功能包括：\n",
      "\n",
      "1. 文件读取\n",
      "TextLoader 可以读取本地文本文件，支持指定文件编码格式。\n",
      "\n",
      "2. 文档转换\n",
      "将文本文件内容转换为 LangChain 的 Document 对象，包含：\n",
      "- page_content：文档的文本内容\n",
      "- metadata：文档的元数据（如文件路径、编码格式等）\n",
      "\n",
      "3. 编码处理\n",
      "TextLoader 支持多种字符编码，包括：\n",
      "- UTF-8：国际通用编码，支持所有 Unicode 字符\n",
      "- GBK：中文 Windows 系统常用编码\n",
      "- ASCII：基础英文字符编码\n",
      "\n",
      "4. 元数据管理\n",
      "自动提取并存储文档的元数据信息，如：\n",
      "- source：文件路径\n",
      "- encoding：文件编码格式\n",
      "\n",
      "四、使用示例\n",
      "\n",
      "使用 TextLoader 加载文档非常简单：\n",
      "\n",
      "```python\n",
      "from langchain_community.document_loaders import TextLoader\n",
      "\n",
      "# 创建 TextLoader 实例\n",
      "loader = TextLoader(\n",
      "    file_path=\"./document.txt\",\n",
      "    encoding=\"utf-8\"\n",
      ")\n",
      "\n",
      "# 加载文档\n",
      "docs = loader.load()\n",
      "\n",
      "# 访问文档内容\n",
      "print(docs[0].page_content)  # 文档文本内容\n",
      "print(docs[0].metadata)      # 文档元数据\n",
      "```\n",
      "\n",
      "五、应用场景\n",
      "\n",
      "TextLoader 适用于以下场景：\n",
      "- 加载纯文本配置文件\n",
      "- 读取日志文件进行分析\n",
      "- 处理代码文件\n",
      "- 加载结构化的文本数据\n",
      "- RAG（检索增强生成）应用中的文档加载\n",
      "\n",
      "六、总结\n",
      "\n",
      "LangChain 的 TextLoader 为开发者提供了一个简单而强大的工具来加载和处理文本文件。通过正确使用 TextLoader，开发者可以轻松地将文本文件集成到 LangChain 应用的工作流中，为后续的文档处理、向量化、检索等操作奠定基础。\n",
      "\n",
      "无论是处理简单的配置文件，还是构建复杂的 RAG 系统，TextLoader 都是 LangChain 生态系统中不可或缺的基础组件。\n",
      "\n",
      "====================\n",
      "docs: [Document(metadata={'source': './document/load/01-langchain-utf-8.txt'}, page_content='LangChain 框架核心介绍\\n\\n一、什么是 LangChain\\n\\nLangChain 是一个用于构建基于大语言模型（LLM）应用的开发框架，旨在帮助开发者更高效地集成、管理和增强大语言模型的能力，构建端到端的应用程序。\\n\\n它提供了一套模块化工具和接口，支持从简单的文本生成到复杂的多步骤推理任务。\\n\\n二、核心特性\\n\\n1. 模块化设计\\nLangChain 采用模块化架构，开发者可以根据需求选择和使用不同的组件。主要模块包括：\\n- 文档加载器（Document Loaders）：支持从各种数据源加载文档\\n- 文本分割器（Text Splitters）：将长文本分割成适合处理的块\\n- 向量存储（Vector Stores）：存储和检索文档的向量表示\\n- 链（Chains）：将多个组件串联起来执行复杂任务\\n- 代理（Agents）：让 LLM 能够自主决策和调用工具\\n- 记忆（Memory）：管理对话历史和上下文信息\\n\\n2. 丰富的集成能力\\nLangChain 支持与多种 LLM 提供商集成，包括：\\n- OpenAI GPT 系列模型\\n- 开源模型（如 Llama、Mistral 等）\\n- 本地部署的模型\\n\\n3. 强大的文档处理能力\\n通过 TextLoader 等文档加载器，LangChain 可以：\\n- 加载各种格式的文档（TXT、PDF、HTML、Markdown 等）\\n- 处理不同编码的文本文件（UTF-8、GBK 等）\\n- 提取文档的元数据信息\\n- 将文档转换为标准化的 Document 对象\\n\\n三、TextLoader 的作用\\n\\nTextLoader 是 LangChain 中最基础的文档加载器之一，它的主要功能包括：\\n\\n1. 文件读取\\nTextLoader 可以读取本地文本文件，支持指定文件编码格式。\\n\\n2. 文档转换\\n将文本文件内容转换为 LangChain 的 Document 对象，包含：\\n- page_content：文档的文本内容\\n- metadata：文档的元数据（如文件路径、编码格式等）\\n\\n3. 编码处理\\nTextLoader 支持多种字符编码，包括：\\n- UTF-8：国际通用编码，支持所有 Unicode 字符\\n- GBK：中文 Windows 系统常用编码\\n- ASCII：基础英文字符编码\\n\\n4. 元数据管理\\n自动提取并存储文档的元数据信息，如：\\n- source：文件路径\\n- encoding：文件编码格式\\n\\n四、使用示例\\n\\n使用 TextLoader 加载文档非常简单：\\n\\n```python\\nfrom langchain_community.document_loaders import TextLoader\\n\\n# 创建 TextLoader 实例\\nloader = TextLoader(\\n    file_path=\"./document.txt\",\\n    encoding=\"utf-8\"\\n)\\n\\n# 加载文档\\ndocs = loader.load()\\n\\n# 访问文档内容\\nprint(docs[0].page_content)  # 文档文本内容\\nprint(docs[0].metadata)      # 文档元数据\\n```\\n\\n五、应用场景\\n\\nTextLoader 适用于以下场景：\\n- 加载纯文本配置文件\\n- 读取日志文件进行分析\\n- 处理代码文件\\n- 加载结构化的文本数据\\n- RAG（检索增强生成）应用中的文档加载\\n\\n六、总结\\n\\nLangChain 的 TextLoader 为开发者提供了一个简单而强大的工具来加载和处理文本文件。通过正确使用 TextLoader，开发者可以轻松地将文本文件集成到 LangChain 应用的工作流中，为后续的文档处理、向量化、检索等操作奠定基础。\\n\\n无论是处理简单的配置文件，还是构建复杂的 RAG 系统，TextLoader 都是 LangChain 生态系统中不可或缺的基础组件。\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# 指定要加载的文本文件路径\n",
    "file_path = \"./document/load/01-langchain-utf-8.txt\"\n",
    "\n",
    "# 创建 TextLoader 实例，指定文件路径和编码格式\n",
    "text_loader = TextLoader(\n",
    "    file_path=file_path,\n",
    "    encoding=\"utf-8\",  # 指定 UTF-8 编码，支持中文字符,需要和原文本的编码格式相同\n",
    ")\n",
    "\n",
    "# 加载文档，返回 Document 对象列表\n",
    "docs = text_loader.load()\n",
    "\n",
    "# 查看加载的文档数量\n",
    "print(f\"docs len: {len(docs)}\")\n",
    "print(f\"docs type: {type(docs[0])}\")  # <class 'langchain_core.documents.base.Document'>\n",
    "print(f\"docs metadata: {docs[0].metadata}\")  # {'source': './document/load/01-langchain-utf-8.txt'}\n",
    "print(f\"docs page_content: {docs[0].page_content}\")\n",
    "print(\"=\" * 20)\n",
    "print(f\"docs: {docs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505ca91",
   "metadata": {},
   "source": [
    "### 1.2、关键特性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d58b955cc8288",
   "metadata": {},
   "source": [
    "1）编码支持\n",
    "TextLoader 支持多种字符编码格式：\n",
    "- **UTF-8**：国际通用编码，支持所有 Unicode 字符（包括中文、日文、韩文等）\n",
    "- **GBK**：中文 Windows 系统常用编码\n",
    "- **ASCII**：基础英文字符编码\n",
    "\n",
    "2）文档对象结构\n",
    "TextLoader 将文本文件转换为 `Document` 对象，包含：\n",
    "- **page_content**：文档的文本内容（字符串）\n",
    "- **metadata**：文档的元数据（字典），通常包含：\n",
    "  - `source`: 文件路径\n",
    "  - `encoding`:文件编码格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a14fa",
   "metadata": {},
   "source": [
    "### 1.3、注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32def02a2697db6b",
   "metadata": {},
   "source": [
    "- 1) **文件路径**：确保文件路径正确，可以使用相对路径或绝对路径\n",
    "- 2) **编码格式**：如果文件包含中文或其他非 ASCII 字符，务必指定正确的编码格式\n",
    "- 3) **文件大小**：TextLoader 会将整个文件加载到内存中，对于超大文件需要考虑使用其他加载器\n",
    "- 4) **文档分割**：TextLoader 将整个文件作为一个 Document 对象返回，如需分割文档，需要使用 TextSplitter\n",
    "- 5) **元数据**：可以通过 metadata 参数添加自定义元数据信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9531466e804d00c4",
   "metadata": {},
   "source": [
    "## 2、PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36322a2400afc2fe",
   "metadata": {},
   "source": [
    "- LangChain加载PDF文件使用的是pypdf，先安装依赖库:  pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428e6127a67b2d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:23:59.525377Z",
     "start_time": "2025-11-11T01:23:59.512652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs len: 1\n",
      "docs metadata: {'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-06-20T17:18:19+08:00', 'moddate': '2025-06-20T17:18:19+08:00', 'source': './document/load/02-load.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n",
      "docs page_content: \"他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不\n",
      "知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。\n",
      "那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想\n",
      "着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。\" \n",
      " \n",
      "\"他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他\n",
      "只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想\n",
      "的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地\n",
      "会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！\n",
      "\"\n",
      "====================\n",
      "page_content='\"他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不\n",
      "知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。\n",
      "那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想\n",
      "着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。\" \n",
      " \n",
      "\"他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他\n",
      "只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想\n",
      "的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地\n",
      "会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！\n",
      "\"' metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-06-20T17:18:19+08:00', 'moddate': '2025-06-20T17:18:19+08:00', 'source': './document/load/02-load.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(file_path=\"./document/load/02-load.pdf\")\n",
    "\n",
    "docs = pdf_loader.load()\n",
    "\n",
    "print(f\"docs len: {len(docs)}\")\n",
    "print(f\"docs metadata: {docs[0].metadata}\")\n",
    "print(f\"docs page_content: {docs[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a706d41fef5c2567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T01:25:25.029637Z",
     "start_time": "2025-11-11T01:25:25.005032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-06-20T17:18:19+08:00', 'moddate': '2025-06-20T17:18:19+08:00', 'source': './document/load/02-load.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='\"他的车，他的命！ 他忽然想起来，一年，二年，至少有三四年；一滴汗，两滴汗，不\\n知道多少万滴汗，才挣出那辆车。从风里雨里的咬牙，从饭里茶里的自苦，才赚出那辆车。\\n那辆车是他的一切挣扎与困苦的总结果与报酬，像身经百战的武士的一颗徽章。……他老想\\n着远远的一辆车，可以使他自由，独立，像自己的手脚的那么一辆车。\" \\n \\n\"他吃，他喝，他嫖，他赌，他懒，他狡猾， 因为他没了心，他的心被人家摘了去。他\\n只剩下那个高大的肉架子，等着溃烂，预备着到乱死岗子去。……体面的、要强的、好梦想\\n的、利己的、个人的、健壮的、伟大的祥子，不知陪着人家送了多少回殡；不知道何时何地\\n会埋起他自己来， 埋起这堕落的、 自私的、 不幸的、 社会病胎里的产儿， 个人主义的末路鬼！\\n\"')]\n"
     ]
    }
   ],
   "source": [
    "docs = pdf_loader.load_and_split() #底层默认使用了递归字符文本切分器\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb3fcd9d9286c6",
   "metadata": {},
   "source": [
    "PyPDFLoader,依然是使用 .page_content 和 .metadata 去访问数据, 即每一个文档加载器虽然代码逻辑不同，应用需求不同，但使用方式是相同的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ecfae865c241a8",
   "metadata": {},
   "source": [
    "## 3.CSVLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f100b997937fb",
   "metadata": {},
   "source": [
    "- 加载csv中的所有列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0471b713bbc9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T02:26:22.251286Z",
     "start_time": "2025-11-11T02:26:22.244281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'list'>\n",
      "data[0] type:<class 'langchain_core.documents.base.Document'>\n",
      "len(data):4\n",
      "====================\n",
      "data: [Document(metadata={'source': './document/load/03-load.csv', 'row': 0}, page_content='id: 1\\ntitle: Introduction to Python\\ncontent: Python is a popular programming language.\\nauthor: Guido van Rossum'), Document(metadata={'source': './document/load/03-load.csv', 'row': 1}, page_content='id: 2\\ntitle: Data Science Basics\\ncontent: Data science involves statistics and machine learning.\\nauthor: Jane Smith'), Document(metadata={'source': './document/load/03-load.csv', 'row': 2}, page_content='id: 3\\ntitle: Web Development\\ncontent: HTML, CSS and JavaScript are core web technologies.\\nauthor: Mike Johnson'), Document(metadata={'source': './document/load/03-load.csv', 'row': 3}, page_content='id: 4\\ntitle: Artificial Intelligence\\ncontent: AI is transforming many industries.\\nauthor: Sarah Williams')]\n",
      "page_content='id: 1\n",
      "title: Introduction to Python\n",
      "content: Python is a popular programming language.\n",
      "author: Guido van Rossum' metadata={'source': './document/load/03-load.csv', 'row': 0}\n",
      "page_content='id: 2\n",
      "title: Data Science Basics\n",
      "content: Data science involves statistics and machine learning.\n",
      "author: Jane Smith' metadata={'source': './document/load/03-load.csv', 'row': 1}\n",
      "page_content='id: 3\n",
      "title: Web Development\n",
      "content: HTML, CSS and JavaScript are core web technologies.\n",
      "author: Mike Johnson' metadata={'source': './document/load/03-load.csv', 'row': 2}\n",
      "page_content='id: 4\n",
      "title: Artificial Intelligence\n",
      "content: AI is transforming many industries.\n",
      "author: Sarah Williams' metadata={'source': './document/load/03-load.csv', 'row': 3}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"./document/load/03-load.csv\")\n",
    "\n",
    "# 加载csv中的所有列\n",
    "data = loader.load()\n",
    "\n",
    "print(f\"data type: {type(data)}\")  # <class 'list'>\n",
    "print(f\"data[0] type:{type(data[0])}\") # <class 'langchain_core.documents.base.Document'>\n",
    "print(f\"len(data):{len(data)}\")  # 4\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(f\"data: {data}\")\n",
    "for e in data:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82536926260947b",
   "metadata": {},
   "source": [
    "- 加载指定列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9867980495c61f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T02:35:52.640755Z",
     "start_time": "2025-11-11T02:35:52.636361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='id: 1\n",
      "title: Introduction to Python\n",
      "content: Python is a popular programming language.\n",
      "author: Guido van Rossum' metadata={'source': 'Introduction to Python', 'row': 0}\n",
      "page_content='id: 2\n",
      "title: Data Science Basics\n",
      "content: Data science involves statistics and machine learning.\n",
      "author: Jane Smith' metadata={'source': 'Data Science Basics', 'row': 1}\n",
      "page_content='id: 3\n",
      "title: Web Development\n",
      "content: HTML, CSS and JavaScript are core web technologies.\n",
      "author: Mike Johnson' metadata={'source': 'Web Development', 'row': 2}\n",
      "page_content='id: 4\n",
      "title: Artificial Intelligence\n",
      "content: AI is transforming many industries.\n",
      "author: Sarah Williams' metadata={'source': 'Artificial Intelligence', 'row': 3}\n"
     ]
    }
   ],
   "source": [
    "loader = CSVLoader(\n",
    "    file_path=\"./document/load/03-load.csv\",\n",
    "    source_column='title'  # 用指定加载列的数据 覆盖 metadata中source的值\n",
    ")\n",
    "data = loader.load()\n",
    "\n",
    "for e in  data:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d30cd60df00427",
   "metadata": {},
   "source": [
    "## 4、JSONLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8738d7be86c7a06",
   "metadata": {},
   "source": [
    "- LangChain提供的JSON格式的文档加载器是 JSONLoader,需要安装第三方库:  pip install jq\n",
    "- 在实际应用场景中，JSON格式的数据占有很大比例,且JSON的形式也是多样的,需要特别关注。\n",
    "- JSONLoader 使用指定的 jq结构来解析 JSON 文件。jq是一个轻量级的命令行 JSON 处理器,可以对JSON格式的数据进行数据过滤、映射、减少和转换等各种复杂的处理操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d822f6677e65dc",
   "metadata": {},
   "source": [
    " - 加载所有列(metadata中source值为加载文件的路径)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "635cb9266b1f7713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T03:04:50.146190Z",
     "start_time": "2025-11-11T03:04:50.138028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'list'>\n",
      "data len: 1\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "page_content='{\"msglist\": [{\"sender\": \"Alice\", \"content\": \"Hello, how are you today?\", \"timestamp\": \"2023-05-15T10:00:00\"}, {\"sender\": \"Bob\", \"content\": \"I'm doing well, thanks for asking!\", \"timestamp\": \"2023-05-15T10:02:00\"}, {\"sender\": \"Alice\", \"content\": \"Would you like to meet for lunch?\", \"timestamp\": \"2023-05-15T10:05:00\"}, {\"sender\": \"Bob\", \"content\": \"Sure, that sounds great!\", \"timestamp\": \"2023-05-15T10:07:00\"}], \"conversation_id\": \"conv_12345\", \"participants\": [\"Alice\", \"Bob\"]}' metadata={'source': 'D:\\\\ai-in-action\\\\langchain-in-action\\\\retrieval\\\\document\\\\load\\\\04-load.json', 'seq_num': 1}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.json_loader import JSONLoader\n",
    "\n",
    "# 错误的写法:\n",
    "# loader = JSONLoader(file_path=\"./document/load/03-load.json\")\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path=\"./document/load/04-load.json\",\n",
    "    jq_schema=\".\",  #直接提取完整的JSON对象（包括所有字段）\n",
    "    text_content=False  # 将加载的JSON对象转化为字符串\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data = loader.load()\n",
    "print(f\"data type: {type(data)}\")\n",
    "print(f\"data len: {len(data)}\")\n",
    "print(\"=-\" * 20)\n",
    "for e in data:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80f387901da1c",
   "metadata": {},
   "source": [
    "- 加载JSON文件中msglist的所有content字段(会用content字段覆盖掉 原metadata中的source值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1ecab5b1a2a8d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T03:03:37.472124Z",
     "start_time": "2025-11-11T03:03:37.465407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Hello, how are you today?' metadata={'source': 'D:\\\\ai-in-action\\\\langchain-in-action\\\\retrieval\\\\document\\\\load\\\\04-load.json', 'seq_num': 1}\n",
      "page_content='I'm doing well, thanks for asking!' metadata={'source': 'D:\\\\ai-in-action\\\\langchain-in-action\\\\retrieval\\\\document\\\\load\\\\04-load.json', 'seq_num': 2}\n",
      "page_content='Would you like to meet for lunch?' metadata={'source': 'D:\\\\ai-in-action\\\\langchain-in-action\\\\retrieval\\\\document\\\\load\\\\04-load.json', 'seq_num': 3}\n",
      "page_content='Sure, that sounds great!' metadata={'source': 'D:\\\\ai-in-action\\\\langchain-in-action\\\\retrieval\\\\document\\\\load\\\\04-load.json', 'seq_num': 4}\n"
     ]
    }
   ],
   "source": [
    "loader = JSONLoader(\n",
    "     file_path=\"./document/load/04-load.json\",\n",
    "     jq_schema=\".msglist[].content\",\n",
    ")\n",
    "data = loader.load()\n",
    "for e in data:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa2c751d7bfe1f",
   "metadata": {},
   "source": [
    "- 提取JSON中的嵌套字段、数组元素,可使用`content_key`配合`is_content_key_jq_parsable=True`,通过 jq 语法精准定位目标数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0f1ea6e6ac01c37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T07:10:39.916630Z",
     "start_time": "2025-11-11T07:10:39.892018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'list'>\n",
      "Understanding JSONLoader => This article explains how to parse API responses...\n",
      "Advanced jq Schema Patterns => Learn to handle nested structures with...\n",
      "LangChain Metadata Handling => Best practices for preserving metadata...\n"
     ]
    }
   ],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path=\"./document/load/04-response.json\",\n",
    "    jq_schema=\".data.items[]\",\n",
    "    content_key='.title + \" => \" + .content',\n",
    "    is_content_key_jq_parsable=True   # 使用jq解析title和content\n",
    ")\n",
    "data = loader.load()\n",
    "print(f\"data type: {type(data)}\")\n",
    "for e in data:\n",
    "    print(e.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
